import os
import re

import streamlit as st
from langchain.callbacks.base import BaseCallbackHandler
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import UnstructuredFileLoader
from langchain.embeddings import CacheBackedEmbeddings, OpenAIEmbeddings
from langchain.output_parsers import RegexParser
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.runnable.base import RunnableLambda
from langchain.storage import LocalFileStore
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores.faiss import FAISS

st.set_page_config(
    page_title="DocumentQuiz",
    page_icon="ğŸ“š",
)


class QuizCallbackHandler(BaseCallbackHandler):
    def __init__(self):
        self.message = ''
        self.message_box = None

    def on_llm_start(self, *args, **kwargs):
        self.message_box = st.empty()
        self.message = ""

    def on_llm_new_token(self, token: str, *args, **kwargs):
        self.message += token
        if self.message_box is not None:
            self.message_box.markdown(self.message)

    def on_llm_end(self, *args, **kwargs):
        pass


@st.cache_data(show_spinner="Embedding file...")
def embed_file(original_file, api_key_input):
    os.makedirs("./.cache/files", exist_ok=True)
    file_content = original_file.read()
    file_path = f"./.cache/files/{original_file.name}"
    with open(file_path, "wb") as f:
        f.write(file_content)

    cache_dir = LocalFileStore(f"./.cache/embeddings/{original_file.name}")

    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
    )

    # ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
    loader = UnstructuredFileLoader(file_path)
    docs = loader.load_and_split(text_splitter=splitter)

    # ì„ë² ë”© ìƒì„±
    embeddings = OpenAIEmbeddings(openai_api_key=api_key_input)
    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(
        embeddings, cache_dir)

    # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    vectorstore = FAISS.from_documents(docs, cached_embeddings)
    retriever = vectorstore.as_retriever()

    return retriever, docs


def format_docs(docs):
    return "\n\n".join(document.page_content for document in docs)


def parse_quiz_response(response_text):
    """Parse the quiz response using regex patterns"""

    questions = []

    # Split by question markers
    question_blocks = re.split(r'ë¬¸ì œ\s*\d+:', response_text)

    for block in question_blocks[1:]:  # Skip first empty split
        try:
            # Extract question text
            question_match = re.search(
                r'^([^A-D]*?)(?=A\)|ì„ íƒì§€)', block.strip(), re.MULTILINE | re.DOTALL)
            if not question_match:
                continue

            question = question_match.group(1).strip()

            # Extract options
            option_a = re.search(r'A\)\s*([^\n]*(?:\n(?!B\))[^\n]*)*)', block)
            option_b = re.search(r'B\)\s*([^\n]*(?:\n(?!C\))[^\n]*)*)', block)
            option_c = re.search(r'C\)\s*([^\n]*(?:\n(?!D\))[^\n]*)*)', block)
            option_d = re.search(
                r'D\)\s*([^\n]*(?:\n(?!ì •ë‹µ|í•´ì„¤)[^\n]*)*)', block)

            # Extract correct answer
            answer_match = re.search(r'ì •ë‹µ[:\s]*([A-D])', block)

            # Extract explanation
            explanation_match = re.search(
                r'(?:í•´ì„¤|ì„¤ëª…)[:\s]*(.+?)(?=ë¬¸ì œ\s*\d+:|$)', block, re.DOTALL)

            if all([question, option_a, option_b, option_c, option_d, answer_match]):
                questions.append({
                    'question': question,
                    'option_a': option_a.group(1).strip(),
                    'option_b': option_b.group(1).strip(),
                    'option_c': option_c.group(1).strip(),
                    'option_d': option_d.group(1).strip(),
                    'correct_answer': answer_match.group(1),
                    'explanation': explanation_match.group(1).strip() if explanation_match else "ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤."
                })
        except Exception as e:
            continue

    return questions


@st.cache_data(show_spinner="Generating quiz...")
def generate_quiz(full_content, api_key_input, difficulty, num_questions, _file_hash):
    """Generate quiz using structured prompts with caching"""

    # Create LLM
    llm = ChatOpenAI(
        api_key=api_key_input,
        model="gpt-4o-mini",
        temperature=0.1,
    )

    # Create the quiz generation prompt
    difficulty_instructions = {
        "easy": "ê¸°ë³¸ì ì¸ ë‚´ìš© ì´í•´ì™€ ì‚¬ì‹¤ í™•ì¸ì„ ìœ„í•œ ì‰¬ìš´ ë¬¸ì œë“¤ì„ ë§Œë“œì„¸ìš”.",
        "medium": "ê°œë… ì´í•´ì™€ ê´€ê³„ íŒŒì•…ì´ í•„ìš”í•œ ë³´í†µ ìˆ˜ì¤€ì˜ ë¬¸ì œë“¤ì„ ë§Œë“œì„¸ìš”.",
        "hard": "ë¹„íŒì  ì‚¬ê³ ì™€ ë¶„ì„ì´ í•„ìš”í•œ ì–´ë ¤ìš´ ë¬¸ì œë“¤ì„ ë§Œë“œì„¸ìš”."
    }

    # Create example format
    example_format = """
ë¬¸ì œ 1: ì—¬ê¸°ì— ë¬¸ì œë¥¼ ì‘ì„±í•˜ì„¸ìš”
A) ì²« ë²ˆì§¸ ì„ íƒì§€
B) ë‘ ë²ˆì§¸ ì„ íƒì§€  
C) ì„¸ ë²ˆì§¸ ì„ íƒì§€
D) ë„¤ ë²ˆì§¸ ì„ íƒì§€
ì •ë‹µ: A
í•´ì„¤: ì •ë‹µì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.

ë¬¸ì œ 2: ë‹¤ìŒ ë¬¸ì œë¥¼ ì‘ì„±í•˜ì„¸ìš”
A) ì²« ë²ˆì§¸ ì„ íƒì§€
B) ë‘ ë²ˆì§¸ ì„ íƒì§€
C) ì„¸ ë²ˆì§¸ ì„ íƒì§€  
D) ë„¤ ë²ˆì§¸ ì„ íƒì§€
ì •ë‹µ: B
í•´ì„¤: ì •ë‹µì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì„ ì‘ì„±í•˜ì„¸ìš”.
"""

    prompt = ChatPromptTemplate.from_messages([
        ("system", f"""
        ë‹¹ì‹ ì€ í€´ì¦ˆ ìƒì„±ê¸°ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ ê°ê´€ì‹ ë¬¸ì œë¥¼ ë§Œë“œì„¸ìš”.
        
        ë‚œì´ë„: {difficulty}
        ì§€ì¹¨: {difficulty_instructions.get(difficulty, difficulty_instructions["medium"])}
        
        ë‹¤ìŒ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì„œ ì‘ì„±í•˜ì„¸ìš”:
        {example_format}
        
        í•„ìˆ˜ ìš”êµ¬ì‚¬í•­:
        1. ëª¨ë“  ë¬¸ì œì™€ ì„ íƒì§€ëŠ” í•œêµ­ì–´ë¡œ ì‘ì„±
        2. ê° ë¬¸ì œëŠ” ì •í™•íˆ 4ê°œì˜ ì„ íƒì§€ (A, B, C, D)
        3. "ë¬¸ì œ X:" í˜•ì‹ìœ¼ë¡œ ë¬¸ì œ ë²ˆí˜¸ í‘œì‹œ
        4. ì„ íƒì§€ëŠ” "A) ë‚´ìš©" í˜•ì‹ìœ¼ë¡œ ì‘ì„±
        5. "ì •ë‹µ: X" í˜•ì‹ìœ¼ë¡œ ì •ë‹µ í‘œì‹œ
        6. "í•´ì„¤: ë‚´ìš©" í˜•ì‹ìœ¼ë¡œ ì„¤ëª… ì‘ì„±
        7. ê° ë¬¸ì œ ì‚¬ì´ì— ë¹ˆ ì¤„ ì¶”ê°€
        8. ë¬¸ì„œ ë‚´ìš©ì„ ì •í™•íˆ ë°˜ì˜í•œ ë¬¸ì œ ì‘ì„±
        
        ë°˜ë“œì‹œ ìœ„ì˜ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼ì£¼ì„¸ìš”.
        """),
        ("human", "ë¬¸ì„œ ë‚´ìš©: {content}")
    ])

    chain = prompt | llm

    try:
        response = chain.invoke({"content": full_content})
        questions = parse_quiz_response(response.content)

        if len(questions) == 0:
            st.error("í€´ì¦ˆ íŒŒì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            with st.expander("ì›ë³¸ ì‘ë‹µ ë³´ê¸°"):
                st.text(response.content)
            return None

        return {"questions": questions}
    except Exception as e:
        st.error(f"í€´ì¦ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None


def display_quiz(quiz_data):
    """Display the quiz and handle user answers"""

    if 'user_answers' not in st.session_state:
        st.session_state.user_answers = {}

    questions = quiz_data["questions"]

    st.subheader("ğŸ“ í€´ì¦ˆ")

    # Display questions
    for i, question in enumerate(questions):
        st.markdown(f"**ë¬¸ì œ {i+1}:** {question['question']}")

        # Create options list
        options = [
            f"A) {question['option_a']}",
            f"B) {question['option_b']}",
            f"C) {question['option_c']}",
            f"D) {question['option_d']}"
        ]

        # Radio buttons for options
        user_answer = st.radio(
            f"ë‹µì„ ì„ íƒí•˜ì„¸ìš” (ë¬¸ì œ {i+1})",
            options,
            key=f"question_{i}",
            index=None
        )

        if user_answer:
            # Store just the letter (A, B, C, D)
            st.session_state.user_answers[i] = user_answer[0]

        st.markdown("---")

    # Submit button
    if st.button("ë‹µì•ˆ ì œì¶œ", type="primary"):
        if len(st.session_state.user_answers) == len(questions):
            show_results(quiz_data)
        else:
            st.warning("ëª¨ë“  ë¬¸ì œì— ë‹µí•´ì£¼ì„¸ìš”!")


def show_results(quiz_data):
    """Show quiz results and handle retakes"""

    questions = quiz_data["questions"]
    correct_count = 0

    st.subheader("ğŸ“Š ê²°ê³¼")

    # Check answers
    for i, question in enumerate(questions):
        user_answer = st.session_state.user_answers.get(i)
        correct_answer = question['correct_answer']

        if user_answer == correct_answer:
            correct_count += 1
            st.success(f"âœ… ë¬¸ì œ {i+1}: ì •ë‹µ! ({correct_answer})")
        else:
            st.error(
                f"âŒ ë¬¸ì œ {i+1}: ì˜¤ë‹µ (ì •ë‹µ: {correct_answer}, ì„ íƒ: {user_answer})")
            st.info(f"ğŸ’¡ í•´ì„¤: {question['explanation']}")

    # Show final score
    score_percentage = (correct_count / len(questions)) * 100
    st.metric(
        "ì ìˆ˜", f"{correct_count}/{len(questions)} ({score_percentage:.1f}%)")

    # Perfect score celebration
    if correct_count == len(questions):
        st.success("ğŸ‰ ì™„ë²½í•©ë‹ˆë‹¤! ëª¨ë“  ë¬¸ì œë¥¼ ë§ì·„ìŠµë‹ˆë‹¤!")
        st.balloons()
    else:
        st.info(f"ğŸ’ª {len(questions) - correct_count}ê°œ ë¬¸ì œë¥¼ ë” ë§ì¶°ë³´ì„¸ìš”!")

        # Retake button
        if st.button("ë‹¤ì‹œ ì‹œë„í•˜ê¸°", type="secondary"):
            st.session_state.user_answers = {}
            st.session_state.quiz_generated = False
            st.rerun()


# Main UI
st.title("ğŸ“š DocumentQuiz")

st.markdown(
    """
    ì—…ë¡œë“œí•œ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ í€´ì¦ˆë¥¼ ìƒì„±í•˜ê³  í’€ì–´ë³´ì„¸ìš”!
    
    ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í€´ì¦ˆ ì„¤ì •ì„ ì¡°ì •í•˜ì„¸ìš”.
    """
)

with st.sidebar:
    api_key_input = st.text_input(
        'OpenAI APIí‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.',
        type="password",
        help="sk-ë¡œ ì‹œì‘í•˜ëŠ” OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )

    # íŒŒì¼ ì—…ë¡œë“œ
    file = st.file_uploader(
        "Upload a .txt .pdf or .docx file",
        type=["pdf", "txt", "docx"],
    )

    st.markdown("### í€´ì¦ˆ ì„¤ì •")

    # Quiz difficulty
    difficulty = st.selectbox(
        "ë‚œì´ë„ ì„ íƒ",
        ["easy", "medium", "hard"],
        format_func=lambda x: {"easy": "ì‰¬ì›€", "medium": "ë³´í†µ", "hard": "ì–´ë ¤ì›€"}[x]
    )

    # Number of questions
    num_questions = st.slider(
        "ë¬¸ì œ ìˆ˜",
        min_value=3,
        max_value=10,
        value=5
    )

    st.markdown("### ë‚œì´ë„ ì„¤ëª…")
    if difficulty == "easy":
        st.info("ğŸ“– ì†ë…í•˜ë©´ í’€ ìˆ˜ ìˆì–´ìš”!")
    elif difficulty == "medium":
        st.info("ğŸ¤” ì •ë…í•´ì•¼ì§€ í’€ ìˆ˜ ìˆì–´ìš”!")
    else:
        st.info("ğŸ§  ì—¬ëŸ¬ë²ˆ ì •ë…í•´ë´ì•¼í•  ê±°ì—ìš”!")

    st.link_button('Go to Github Repository',
                   "https://github.com/josh3021/fullstack-gpt-nomadcoders")

# Initialize session state
if 'quiz_generated' not in st.session_state:
    st.session_state.quiz_generated = False
if 'current_quiz' not in st.session_state:
    st.session_state.current_quiz = None

if api_key_input and file:
    try:
        # Check if file changed
        if 'current_file' not in st.session_state or st.session_state.get('current_file') != file:
            st.session_state.current_file = file
            st.session_state.quiz_generated = False
            st.session_state.current_quiz = None
            if 'user_answers' in st.session_state:
                del st.session_state.user_answers

        # Embed file
        retriever, docs = embed_file(file, api_key_input)
        full_content = format_docs(docs)

        st.success("âœ… íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

        # Generate quiz button
        if not st.session_state.quiz_generated:
            if st.button("í€´ì¦ˆ ìƒì„±í•˜ê¸°", type="primary"):
                # Create hash for caching
                file_hash = hash(file.name + str(file.size) +
                                 difficulty + str(num_questions))

                quiz_data = generate_quiz(
                    full_content, api_key_input, difficulty, num_questions, file_hash)
                if quiz_data:
                    st.session_state.current_quiz = quiz_data
                    st.session_state.quiz_generated = True
                    st.rerun()

        # Display quiz if generated
        if st.session_state.quiz_generated and st.session_state.current_quiz:
            display_quiz(st.session_state.current_quiz)

            # New quiz button
            if st.button("ìƒˆ í€´ì¦ˆ ìƒì„±", type="secondary"):
                st.session_state.quiz_generated = False
                st.session_state.current_quiz = None
                if 'user_answers' in st.session_state:
                    del st.session_state.user_answers
                st.rerun()

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        st.info("API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

elif not api_key_input:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

elif not file:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
